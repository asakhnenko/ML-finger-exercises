{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Args"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using Flux, Statistics\n",
    "using Parameters: @with_kw\n",
    "\n",
    "using Printf\n",
    "using MLDatasets\n",
    "\n",
    "@with_kw mutable struct Args\n",
    "    learning_rate::Float64 = 3e-4       \n",
    "    batch_size::Int = 1024   \n",
    "    epochs::Int = 10\n",
    "    verbose::Bool = true\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "accuracy (generic function with 1 method)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function load_data(args)\n",
    "    # Loading Dataset\n",
    "    X_train, y_train = MLDatasets.MNIST.traindata(Float32)\n",
    "    X_test,  y_test  = MLDatasets.MNIST.testdata(Float32)\n",
    "\n",
    "    # Preprocessing steps\n",
    "    X_train, X_test = Flux.flatten(X_train), Flux.flatten(X_test)\n",
    "    y_train, y_test = Flux.onehotbatch(y_train, 0:9), Flux.onehotbatch(y_test, 0:9)\n",
    "    \n",
    "    if args.verbose\n",
    "        @printf \"--Loaded Dataset statistics--\\n\"\n",
    "        @printf \"Training data amount :   %d\\n\" size(X_train, 2)\n",
    "        @printf \"Training data size   :   %d\\n\" size(X_train, 1)\n",
    "        @printf \"-----------------------------\\n\"\n",
    "        @printf \"Testing data amount  :   %d\\n\" size(X_test, 2)\n",
    "        @printf \"Testing data size    :   %d\\n\" size(X_test, 1)\n",
    "    end\n",
    "\n",
    "    # Batching\n",
    "    train_data = Flux.Data.DataLoader(X_train, y_train, batchsize=args.batch_size, shuffle=true)\n",
    "    test_data = Flux.Data.DataLoader(X_test, y_test, batchsize=args.batch_size)\n",
    "    \n",
    "    return train_data, test_data\n",
    "end\n",
    "\n",
    "function loss(model)\n",
    "    function (x, y)\n",
    "        Flux.logitcrossentropy(model(x), y)\n",
    "    end\n",
    "end\n",
    "\n",
    "function loss_all(data, loss_func)\n",
    "    loss = 0f0\n",
    "    for (x, y) in data\n",
    "        loss += loss_func(x, y)\n",
    "    end\n",
    "    loss / length(data)\n",
    "end\n",
    "\n",
    "function accuracy(data, model)\n",
    "    accuracy = 0\n",
    "    for (x, y) in data\n",
    "        predicted  = Flux.onecold(cpu(model(x)))\n",
    "        true_label = Flux.onecold(cpu(y))\n",
    "        accuracy += sum(predicted .== true_label) * 1 / size(x, 2)\n",
    "    end\n",
    "    accuracy / length(data)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Loaded Dataset statistics--\n",
      "Training data amount :   60000\n",
      "Training data size   :   784\n",
      "-----------------------------\n",
      "Testing data amount  :   10000\n",
      "Testing data size    :   784\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Epoch 1\n",
      "└ @ Main C:\\Users\\alona\\.julia\\packages\\Flux\\Fj3bt\\src\\optimise\\train.jl:121\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_all(train_data, loss(model)) = 2.3231714f0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Epoch 2\n",
      "└ @ Main C:\\Users\\alona\\.julia\\packages\\Flux\\Fj3bt\\src\\optimise\\train.jl:121\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_all(train_data, loss(model)) = 1.337967f0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Epoch 3\n",
      "└ @ Main C:\\Users\\alona\\.julia\\packages\\Flux\\Fj3bt\\src\\optimise\\train.jl:121\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_all(train_data, loss(model)) = 0.810371f0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Epoch 4\n",
      "└ @ Main C:\\Users\\alona\\.julia\\packages\\Flux\\Fj3bt\\src\\optimise\\train.jl:121\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_all(train_data, loss(model)) = 0.6032391f0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Epoch 5\n",
      "└ @ Main C:\\Users\\alona\\.julia\\packages\\Flux\\Fj3bt\\src\\optimise\\train.jl:121\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_all(train_data, loss(model)) = 0.49972752f0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Epoch 6\n",
      "└ @ Main C:\\Users\\alona\\.julia\\packages\\Flux\\Fj3bt\\src\\optimise\\train.jl:121\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_all(train_data, loss(model)) = 0.43774837f0\n",
      "loss_all(train_data, loss(model)) = 0.39761862f0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Epoch 7\n",
      "└ @ Main C:\\Users\\alona\\.julia\\packages\\Flux\\Fj3bt\\src\\optimise\\train.jl:121\n",
      "┌ Info: Epoch 8\n",
      "└ @ Main C:\\Users\\alona\\.julia\\packages\\Flux\\Fj3bt\\src\\optimise\\train.jl:121\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_all(train_data, loss(model)) = 0.36809814f0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Epoch 9\n",
      "└ @ Main C:\\Users\\alona\\.julia\\packages\\Flux\\Fj3bt\\src\\optimise\\train.jl:121\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_all(train_data, loss(model)) = 0.34596434f0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Epoch 10\n",
      "└ @ Main C:\\Users\\alona\\.julia\\packages\\Flux\\Fj3bt\\src\\optimise\\train.jl:121\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_all(train_data, loss(model)) = 0.32793108f0\n"
     ]
    }
   ],
   "source": [
    "args = Args()\n",
    "\n",
    "# Loading Data\n",
    "train_data, test_data = load_data(args)\n",
    "\n",
    "# Constructing the model\n",
    "model = Chain(\n",
    "    Dense(28 * 28, 32, relu),\n",
    "    Dense(32, 10)\n",
    ")\n",
    "\n",
    "# Training\n",
    "evalcb = () -> @show(loss_all(train_data, loss(model)))\n",
    "optimizer = ADAM(args.learning_rate)\n",
    "\n",
    "Flux.@epochs args.epochs Flux.train!(\n",
    "    loss(model), \n",
    "    params(model), \n",
    "    train_data, \n",
    "    optimizer, \n",
    "    cb = Flux.throttle(evalcb, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy on training data:   91.517 \n",
      "Model accuracy on testing data :   91.504 \n"
     ]
    }
   ],
   "source": [
    "@printf \"Model accuracy on training data:   %0.3f \\n\" accuracy(train_data, model) * 100\n",
    "@printf \"Model accuracy on testing data :   %0.3f \\n\" accuracy(test_data, model) * 100"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.4.1",
   "language": "julia",
   "name": "julia-1.4"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
